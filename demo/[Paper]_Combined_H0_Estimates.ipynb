{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lenstronomy\n",
    "print(lenstronomy.__path__)\n",
    "from h0rton.configs import TrainValConfig, TestConfig\n",
    "from baobab.configs import BaobabConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import h0rton.tdlmc_utils as tdlmc_utils\n",
    "import baobab.sim_utils as sim_utils\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotting params\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rc('font', family='STIXGeneral', size=20)\n",
    "plt.rc('xtick', labelsize='medium')\n",
    "plt.rc('ytick', labelsize='medium')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('axes', linewidth=2, titlesize='large', labelsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined H0 estimate\n",
    "\n",
    "__Author:__ Ji Won Park (@jiwoncpark)\n",
    "\n",
    "__Created:__ 8/20/2020\n",
    "\n",
    "__Last run:__ 11/29/2020\n",
    "\n",
    "__Goals:__\n",
    "We plot the results of combining lenses under various binning schemes, including\n",
    "\n",
    "- all the lenses (no binning)\n",
    "- doubles vs. quads\n",
    "- Einstein brightness quartiles\n",
    "\n",
    "__Before_running:__\n",
    "1. Train the BNN, e.g.\n",
    "```bash\n",
    "python h0rton/train.py experiments/v2/train_val_cfg.json\n",
    "```\n",
    "\n",
    "2. Get inference results for the trained model and the precision ceiling, e.g.\n",
    "```bash\n",
    "python h0rton/infer_h0_mcmc_default.py experiments/v2/mcmc_default.json\n",
    "python h0rton/infer_h0_simple_mc_truth.py experiments/v0/simple_mc_default.json\n",
    "```\n",
    "\n",
    "3. Summarize the inference results, e.g.\n",
    "```bash\n",
    "python h0rton/summarize.py 2 mcmc_default\n",
    "python h0rton/summarize.py 0 mcmc_default\n",
    "```\n",
    "\n",
    "4. Combine the individual lens estimates in the above binning schemes, e.g.\n",
    "```bash\n",
    "python h0rton/combine_lenses.py 2 \n",
    "python h0rton/combine_lenses.py 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Diagnostic plots](#diagnostic_plots)\n",
    "2. [Combined H0 plots](#combined_h0_plots)\n",
    "    1. [Doubles vs. quads](#doubles_quads)\n",
    "    2. [Exposure times](#exposure_times)\n",
    "    3. [Gamma retrieval vs. Einstein ring brightness](#gamma)\n",
    "    4. [Gamma retrieval vs. other metrics](#gamma_other_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 200 # number of lenses to visualize\n",
    "version_id = 3 # ID of the version folder in experiments\n",
    "prec_version_id = 0 # ID of the version folder corresponding to precision ceiling\n",
    "true_H0 = 70.0\n",
    "true_Om0 = 0.3\n",
    "save_fig = True\n",
    "\n",
    "version_dir = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(version_id)\n",
    "test_cfg_path = os.path.join(version_dir, 'mcmc_default.json')\n",
    "test_cfg = TestConfig.from_file(test_cfg_path)\n",
    "baobab_cfg = BaobabConfig.from_file(test_cfg.data.test_baobab_cfg_path)\n",
    "train_val_cfg = TrainValConfig.from_file(test_cfg.train_val_config_file_path)\n",
    "# Read in truth metadata\n",
    "metadata = pd.read_csv(os.path.join(baobab_cfg.out_dir, 'metadata.csv'), index_col=None, nrows=n_test)\n",
    "# Read in summary\n",
    "summary = pd.read_csv(os.path.join(version_dir, 'summary.csv'), index_col=None, nrows=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant lenses\n",
    "summary.drop(summary[summary['id']>(n_test - 1)].index, inplace=True)\n",
    "outside_rung = summary[summary['inference_time'] == 0].index\n",
    "summary.drop(outside_rung, inplace=True)\n",
    "print(\"Number of lenses being combined: {:d}\".format(summary.shape[0]))\n",
    "print(\"Lenses that were discarded: \", set(np.arange(n_test)) - set(summary['id'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic plots <a name=\"diagnostic_plots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1.0/summary['H0_std'].values**2.0 # weight each lens by the inverse H0 variance\n",
    "weighted_mean = np.average(summary['H0_mean'], weights=w) \n",
    "summary['z'] = (summary['H0_mean'] - weighted_mean)/summary['H0_std'] # deviations from weighted mean\n",
    "summary['z_from_true'] = (summary['H0_mean'] - true_H0)/summary['H0_std'] # deviations from true H0\n",
    "weighted_std = np.average((summary['H0_mean'].values - weighted_mean)**2, weights=w)**0.5 # deviations from weighted mean and weighted std\n",
    "summary['z_weighted_std'] = (summary['H0_mean'].values - weighted_mean)/weighted_std\n",
    "print(\"weighted mean: \", weighted_mean)\n",
    "print(\"weighted std: \", weighted_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of H0 z\n",
    "plt.hist(summary['z_weighted_std'].values, bins=20, density=True)\n",
    "z_grid = np.linspace(-4, 4, 100)\n",
    "plt.plot(z_grid, norm.pdf(z_grid, 0, 1), label='N(0, 1)')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('something like z')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(version_dir, 'something_like_z.png'), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.hist(summary['inference_time'].values)\n",
    "print(np.median(summary['inference_time'].values))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of H0 std\n",
    "plt.close()\n",
    "plt.hist(summary['H0_std'].values, edgecolor='k', bins=40)\n",
    "print(np.median(summary['H0_std'].values))\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Assigned uncertainty on $H_0$ (km/Mpc/s)')\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(version_dir, 'H0_std.png'), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of H0 mean\n",
    "plt.close()\n",
    "plt.hist(summary['H0_mean'].values, edgecolor='k', bins=20)\n",
    "plt.axvline(true_H0, c='r', linestyle='--', label='truth')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Assigned mean on $H_0$ (km/Mpc/s)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(version_dir, 'H0_mean.png'), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TDLMC metrics\n",
    "summary['keep'] = True # keep all lenses #(np.abs(summary['z']) < 3.0)\n",
    "tdlmc_mean = summary['H0_mean'][summary['keep']]\n",
    "tdlmc_std = summary['H0_std'][summary['keep']]\n",
    "summary['g'] = ((summary['H0_mean'] - true_H0)/summary['H0_std'])**2.0\n",
    "summary['log_g'] = np.log10(summary['g'])\n",
    "summary['p'] = (summary['H0_std']/true_H0)\n",
    "summary['a'] = (summary['H0_mean'] - true_H0)/true_H0\n",
    "G = tdlmc_utils.get_goodness(tdlmc_mean,tdlmc_std, true_H0)\n",
    "P = tdlmc_utils.get_precision(tdlmc_std, true_H0)\n",
    "A = tdlmc_utils.get_accuracy(tdlmc_mean, true_H0)\n",
    "print(\"Goodness of fit: \", G)\n",
    "print(\"Log G: \", np.log10(G))\n",
    "print(\"Precision: \", P)\n",
    "print(\"Accuracy: \", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign doubles vs quads\n",
    "summary['is_quad'] = (summary['n_img'] == 4)\n",
    "print(\"Doubles: \", len(summary[~summary['is_quad']]))\n",
    "print(\"Quads: \", len(summary[summary['is_quad']]))\n",
    "doubles = summary[~summary['is_quad']].iloc[:n_test]\n",
    "quads = summary[summary['is_quad']].iloc[:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_version_dir = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(prec_version_id)\n",
    "prec_summary = pd.read_csv(os.path.join(prec_version_dir, 'ering_summary.csv'), index_col=None, nrows=n_test)\n",
    "summary['lensed_E_ring_mag'] = prec_summary['lensed_E_ring_mag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lensed_ring_bins = np.quantile(summary['lensed_E_ring_mag'].values, [0.25, 0.5, 0.75, 1])\n",
    "lensed_ring_bins[-1] += 0.1 # buffer \n",
    "summary['lensed_ring_bin'] = np.digitize(summary['lensed_E_ring_mag'].values, lensed_ring_bins)\n",
    "\n",
    "plt.close()\n",
    "plt.hist(summary['lensed_E_ring_mag'], edgecolor='k', bins=20)\n",
    "plt.xticks(np.arange(17.0, 24.0, step=1.0))\n",
    "plt.gca().invert_xaxis()\n",
    "for bin_edge in list(lensed_ring_bins):\n",
    "    plt.axvline(bin_edge, color='tab:orange', linestyle='--')\n",
    "plt.xlabel('Einstein ring brightness (mag)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    plt.savefig(os.path.join(version_dir, 'ering_bins.png'), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to test the binning, let's see if the following values end up in the correct bins. Brightest should be bin 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.digitize(np.array([18, 20, 21, 22]), lensed_ring_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(summary['inference_time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary[summary['n_img']==2]['inference_time'].describe()\n",
    "#summary[summary['n_img']==4]['inference_time'].describe()\n",
    "#summary[summary['inference_time']>30]['n_img'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined H0 plots <a name=\"combined_h0_plots\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubles vs. quads <a name=\"doubles_quads\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this\n",
    "orbit_to_ver = dict(zip([0.5, 1, 2, 4], [4, 3, 2]))\n",
    "#orbit_to_ver = dict(zip([4, 1], [1, 3]))\n",
    "orbits_available = [0.5, 1, 2]\n",
    "img_conf_available = ['doubles', 'quads']\n",
    "prec_version = 0\n",
    "\n",
    "include_prec_ceiling = True\n",
    "\n",
    "# This is fixed\n",
    "orbit_to_color = dict(zip([2, 1, 0.5], ['#843c39', '#d6616b', '#e7969c']))# ['#880519', '#c04546', '#f97978']))\n",
    "#colors_dict = dict(zip([0.5, 1, 2, 4],  ['#ffbcaf', '#f4777f', '#cf3759', '#93003a']))\n",
    "orbit_to_seconds = {0.5: '2,700s', 1:'5,400s', 2:'10,800s', 4:'21,600s'}\n",
    "conf_to_x_pos = {'doubles': 0, 'quads': 1}\n",
    "\n",
    "h0_samples_lognormal = {} # h0_samples_lognormal[orbit][doubles/quads] = array of D_dt samples\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    likelihood_type = 'lognormal' #'kde_bandwidth=100'#\n",
    "    version_i = orbit_to_ver[orbit]\n",
    "    version_dir_orbit = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(version_i)\n",
    "    h0_samples_lognormal[orbit] = {}\n",
    "    # Add all lenses combined for this orbit\n",
    "    h0_samples_lognormal[orbit]['all'] =  np.load(os.path.join(version_dir_orbit, 'combined_H0_summary_{:s}.npy'.format(likelihood_type)), allow_pickle=True).squeeze()\n",
    "    # Add doubles, quads combined for this orbit\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        h0_samples_lognormal[orbit][conf] = np.load(os.path.join(version_dir_orbit, 'combined_H0_{:s}_{:s}.npy'.format(conf, likelihood_type)), allow_pickle=True).squeeze()\n",
    "        \n",
    "h0_samples_normal = {} # h0_samples_lognormal[orbit][doubles/quads] = array of D_dt samples\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    #likelihood_type = 'normal'\n",
    "    version_i = orbit_to_ver[orbit]\n",
    "    version_dir_orbit = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(version_i)\n",
    "    h0_samples_normal[orbit] = {}\n",
    "    # Add all lenses combined for this orbit\n",
    "    h0_samples_normal[orbit]['all'] =  np.load(os.path.join(version_dir_orbit, 'combined_H0_summary.npy'), allow_pickle=True).squeeze()\n",
    "    # Add doubles, quads combined for this orbit\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        h0_samples_normal[orbit][conf] = np.load(os.path.join(version_dir_orbit, 'combined_H0_{:s}.npy'.format(conf)), allow_pickle=True).squeeze()\n",
    "        \n",
    "h0_samples_kde = {} # h0_samples_lognormal[orbit][doubles/quads] = array of D_dt samples\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    likelihood_type = 'kde'\n",
    "    version_i = orbit_to_ver[orbit]\n",
    "    version_dir_orbit = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(version_i)\n",
    "    h0_samples_kde[orbit] = {}\n",
    "    # Add all lenses combined for this orbit\n",
    "    h0_samples_kde[orbit]['all'] =  np.load(os.path.join(version_dir_orbit, 'combined_H0_summary_kde.npy'), allow_pickle=True).squeeze()\n",
    "    # Add doubles, quads combined for this orbit\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        h0_samples_kde[orbit][conf] = np.load(os.path.join(version_dir_orbit, 'combined_H0_{:s}_{:s}.npy'.format(conf, likelihood_type)), allow_pickle=True).squeeze()\n",
    "\n",
    "if include_prec_ceiling:\n",
    "    version_dir_prec_orbit = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(prec_version)\n",
    "    h0_samples_kde['prec'] = {}\n",
    "    h0_samples_kde['prec']['all'] =  np.load(os.path.join(version_dir_prec_orbit, 'combined_H0_summary.npy'), allow_pickle=True).squeeze()\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        h0_samples_kde['prec'][conf] = np.load(os.path.join(version_dir_prec_orbit, 'combined_H0_{:s}.npy'.format(conf)), allow_pickle=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "gaussian_samples = np.load(os.path.join('/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(3), 'combined_H0_summary.npy'))\n",
    "gaussian_bins = np.histogram_bin_edges(gaussian_samples, bins='scott')\n",
    "ax.hist(gaussian_samples, bins=gaussian_bins,  density=True, label='Gaussian', histtype='step', color='#d6616b', )\n",
    "\n",
    "lognormal_samples = np.load(os.path.join('/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(3), 'combined_H0_summary_lognormal.npy'))\n",
    "lognormal_bins = np.histogram_bin_edges(lognormal_samples, bins='scott')\n",
    "ax.hist(lognormal_samples, bins=lognormal_bins,  density=True, label='Lognormal', histtype='step', color='#d6616b', hatch='//')\n",
    "\n",
    "#plt.hist(h0_samples_kde['prec']['all'], bins=25, density=True, label='Time delay precision ceiling', histtype='stepfilled', color='tab:gray')\n",
    "prec_lower = np.quantile(h0_samples_kde['prec']['all'], q=0.5 - 0.341, keepdims=False) \n",
    "prec_upper = np.quantile(h0_samples_kde['prec']['all'], q=0.5 + 0.341, keepdims=False) \n",
    "print(prec_lower, prec_upper)\n",
    "y2 = [5, 5]\n",
    "y1 = [0, 0]\n",
    "#plt.fill_between(prec_lower + prec_upper, y2, y1, where=y2>y1, alpha=0.4, color='tab:gray', label='Time delay precision ceiling')\n",
    "#plt.fill_betweenx([0, 10], prec_lower, prec_upper, alpha=1, color='tab:gray', label='Time delay precision ceiling')\n",
    "prec_bins = np.histogram_bin_edges(h0_samples_kde['prec']['all'], bins='scott')\n",
    "ax.hist(h0_samples_kde['prec']['all'], bins=prec_bins, alpha=0.7, density=True, label='Time delay precision ceiling', color='tab:gray')\n",
    "\n",
    "\n",
    "#plt.ylim([0, 1.0])\n",
    "#plt.title('All')\n",
    "ax.axvline(70, color='k', linestyle='--', label='Truth')\n",
    "h0_samples = np.load(os.path.join('/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(3), 'combined_H0_summary_kde.npy'))\n",
    "kde_bins = np.histogram_bin_edges(h0_samples, bins='scott')\n",
    "ax.hist(h0_samples, bins=kde_bins, alpha=0.8, density=True, label='KDE', color='#d6616b')\n",
    "plt.xlim([67, 73])\n",
    "plt.xlabel(\"$H_0$ (km Mpc$^{-1}$ s$^{-1}$)\")\n",
    "plt.ylabel('Density')\n",
    "plt.xticks(np.arange(67, 73 + 1, 1), fontsize=15)\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax.grid(axis=\"x\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "ax.grid(axis=\"x\", color=\"black\", which='minor', alpha=.2,  linestyle=(0, (1, 1)))\n",
    "plt.legend(fontsize=15, loc='upper left')\n",
    "plt.show()\n",
    "#fig.savefig('../kde_vs_lognormal_vs_normal_hist.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "n_bins = len(img_conf_available)\n",
    "\n",
    "# 1-sigma for each exptime, kde\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        means = np.mean(h0_samples_kde[orbit][conf], keepdims=True)\n",
    "        #stds = np.std(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "        upper_sig = np.quantile(h0_samples_kde[orbit][conf], q=0.5 + 0.341, keepdims=True)\n",
    "        lower_sig = np.quantile(h0_samples_kde[orbit][conf], q=0.5 - 0.341, keepdims=True)\n",
    "        print(orbit, conf, means, upper_sig, lower_sig, upper_sig - means)\n",
    "        plt.errorbar(conf_to_x_pos[conf] + orbit_i*0.2 - 0.2, means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=5, capsize=10, label='{:s} HST orbit'.format(str(orbit)))\n",
    "\n",
    "if False:\n",
    "    # 1-sigma for each exptime, lognormal\n",
    "    for orbit_i, orbit in enumerate(orbits_available):\n",
    "        for conf_i, conf in enumerate(img_conf_available):\n",
    "            means = np.mean(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "            #stds = np.std(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "            upper_sig = np.quantile(h0_samples_lognormal[orbit][conf], q=0.5 + 0.341, keepdims=True)\n",
    "            lower_sig = np.quantile(h0_samples_lognormal[orbit][conf], q=0.5 - 0.341, keepdims=True)\n",
    "            print(orbit, conf, means, upper_sig, lower_sig, upper_sig - means)\n",
    "            plt.errorbar(conf_to_x_pos[conf] + orbit_i*0.2 - 0.2, means, yerr=[means-lower_sig, upper_sig-means],\n",
    "                         fmt='o', color=orbit_to_color[orbit], lw=3, capsize=10, label='Lognormal, {:s} HST orbit'.format(str(orbit)))\n",
    "\n",
    "    # 1-sigma for each exptime, normal\n",
    "    for orbit_i, orbit in enumerate(orbits_available):\n",
    "        for conf_i, conf in enumerate(img_conf_available):\n",
    "            means = np.mean(h0_samples_normal[orbit][conf], keepdims=True)\n",
    "            #stds = np.std(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "            upper_sig = np.quantile(h0_samples_normal[orbit][conf], q=0.5 + 0.341, keepdims=True)\n",
    "            lower_sig = np.quantile(h0_samples_normal[orbit][conf], q=0.5 - 0.341, keepdims=True)\n",
    "            print(orbit, conf, means, upper_sig, lower_sig, upper_sig - means)\n",
    "            l, caps, c = plt.errorbar(conf_to_x_pos[conf] + orbit_i*0.2 - 0.2 + 0.05, means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=3, capsize=10, label='Normal, {:s}'.format(orbit_to_seconds[orbit]))\n",
    "            caps[0].set_marker('^')\n",
    "            caps[1].set_marker('v')\n",
    "            c[0].set_linestyle('--')\n",
    "\n",
    "if include_prec_ceiling:\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        prec_means = np.mean(h0_samples_kde['prec'][conf], keepdims=True)\n",
    "        prec_upper_sig = np.quantile(h0_samples_kde['prec'][conf], q=0.5 + 0.341, keepdims=True) \n",
    "        prec_lower_sig = np.quantile(h0_samples_kde['prec'][conf], q=0.5 - 0.341, keepdims=True) \n",
    "        plt.errorbar(conf_to_x_pos[conf] + 0.4, prec_means, yerr=[prec_means-prec_lower_sig, prec_upper_sig-prec_means], fmt='o', color='tab:gray', alpha=1.0, lw=5, capsize=10, label=r'Time delay precision ceiling')\n",
    "\n",
    "plt.plot(np.NaN, np.NaN, '-', color='none', label=' ')\n",
    "# Axis labels, ticks\n",
    "xlabels = ['Doubles', 'Quads']\n",
    "plt.xticks(np.arange(n_bins), labels=xlabels, fontsize=25)\n",
    "plt.xlim([-0.45, len(xlabels) + -1 + 0.65])\n",
    "plt.yticks(np.arange(67, 73 + 1, 0.5), fontsize=25)\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "ax.grid(axis=\"y\", color=\"black\", which='minor', alpha=.2,  linestyle=(0, (1, 1)))\n",
    "plt.ylim([67, 73])\n",
    "\n",
    "plt.axhline(70.0, c='k', linestyle='--', label='Truth = 70 km Mpc$^{-1}$ s$^{-1}$')\n",
    "plt.ylabel(\"$H_0$ (km Mpc$^{-1}$ s$^{-1}$)\", fontsize=30)\n",
    "plt.xlabel(\"Image Configuration\", fontsize=30)\n",
    "#plt.ylabel(\"$H_0\\:(\\\\textbf{km Mpc}^{-1}\\:\\\\textbf{s}^{-1})$\")\n",
    "plt.legend(loc='lower right', ncol=3)\n",
    "handles, legend_labels = plt.gca().get_legend_handles_labels()\n",
    "print(handles, legend_labels)\n",
    "#order = [0, 5, 1, 2, 3, 4]\n",
    "#order = [ -1, 1,0, 3, 5, 7, -7, -5, -3]\n",
    "order = [1, -1, 0, 2, 4, 6]\n",
    "plt.legend([handles[idx] for idx in order], [legend_labels[idx] for idx in order], loc='lower right', fontsize=25, ncol=2)\n",
    "plt.savefig('../boxplot_doubles_vs_quads.pdf', bbox_inches='tight', pad_inches=0) #dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "n_bins = len(img_conf_available)\n",
    "\n",
    "# 1-sigma for each exptime, kde\n",
    "for orbit_i, orbit in enumerate([2]):\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        means = np.mean(h0_samples_kde[orbit][conf], keepdims=True)\n",
    "        #stds = np.std(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "        upper_sig = np.quantile(h0_samples_kde[orbit][conf], q=0.5 + 0.341, keepdims=True)\n",
    "        lower_sig = np.quantile(h0_samples_kde[orbit][conf], q=0.5 - 0.341, keepdims=True)\n",
    "        print(orbit, conf, means, upper_sig, lower_sig, upper_sig - means)\n",
    "        plt.errorbar(conf_to_x_pos[conf] + orbit_i*0.2, means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=5, capsize=10, label='{:s} HST orbit'.format(str(orbit)))\n",
    "\n",
    "if False:\n",
    "    # 1-sigma for each exptime, lognormal\n",
    "    for orbit_i, orbit in enumerate(orbits_available):\n",
    "        for conf_i, conf in enumerate(img_conf_available):\n",
    "            means = np.mean(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "            #stds = np.std(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "            upper_sig = np.quantile(h0_samples_lognormal[orbit][conf], q=0.5 + 0.341, keepdims=True)\n",
    "            lower_sig = np.quantile(h0_samples_lognormal[orbit][conf], q=0.5 - 0.341, keepdims=True)\n",
    "            print(orbit, conf, means, upper_sig, lower_sig, upper_sig - means)\n",
    "            plt.errorbar(conf_to_x_pos[conf] + orbit_i*0.2 - 0.2, means, yerr=[means-lower_sig, upper_sig-means],\n",
    "                         fmt='o', color=orbit_to_color[orbit], lw=3, capsize=10, label='Lognormal, {:s} HST orbit'.format(str(orbit)))\n",
    "\n",
    "    # 1-sigma for each exptime, normal\n",
    "    for orbit_i, orbit in enumerate(orbits_available):\n",
    "        for conf_i, conf in enumerate(img_conf_available):\n",
    "            means = np.mean(h0_samples_normal[orbit][conf], keepdims=True)\n",
    "            #stds = np.std(h0_samples_lognormal[orbit][conf], keepdims=True)\n",
    "            upper_sig = np.quantile(h0_samples_normal[orbit][conf], q=0.5 + 0.341, keepdims=True)\n",
    "            lower_sig = np.quantile(h0_samples_normal[orbit][conf], q=0.5 - 0.341, keepdims=True)\n",
    "            print(orbit, conf, means, upper_sig, lower_sig, upper_sig - means)\n",
    "            l, caps, c = plt.errorbar(conf_to_x_pos[conf] + orbit_i*0.2 - 0.2 + 0.05, means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=3, capsize=10, label='Normal, {:s}'.format(orbit_to_seconds[orbit]))\n",
    "            caps[0].set_marker('^')\n",
    "            caps[1].set_marker('v')\n",
    "            c[0].set_linestyle('--')\n",
    "\n",
    "if include_prec_ceiling:\n",
    "    for conf_i, conf in enumerate(img_conf_available):\n",
    "        prec_means = np.mean(h0_samples_kde['prec'][conf], keepdims=True)\n",
    "        prec_upper_sig = np.quantile(h0_samples_kde['prec'][conf], q=0.5 + 0.341, keepdims=True) \n",
    "        prec_lower_sig = np.quantile(h0_samples_kde['prec'][conf], q=0.5 - 0.341, keepdims=True) \n",
    "        plt.errorbar(conf_to_x_pos[conf] + 0.2, prec_means, yerr=[prec_means-prec_lower_sig, prec_upper_sig-prec_means], fmt='o', color='tab:gray', alpha=1.0, lw=5, capsize=10, label=r'Time delay precision ceiling')\n",
    "\n",
    "plt.plot(np.NaN, np.NaN, '-', color='none', label=' ')\n",
    "# Axis labels, ticks\n",
    "xlabels = ['Doubles', 'Quads']\n",
    "plt.xticks(np.arange(n_bins), labels=xlabels, fontsize=25)\n",
    "plt.xlim([-0.2, 1.4])\n",
    "plt.yticks(np.arange(67, 73 + 1, 0.5), fontsize=25)\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "ax.grid(axis=\"y\", color=\"black\", which='minor', alpha=.2,  linestyle=(0, (1, 1)))\n",
    "plt.ylim([68, 72])\n",
    "\n",
    "plt.axhline(70.0, c='k', linestyle='--', label='Truth = 70 km Mpc$^{-1}$ s$^{-1}$')\n",
    "plt.ylabel(\"$H_0$ (km Mpc$^{-1}$ s$^{-1}$)\", fontsize=30)\n",
    "plt.xlabel(\"Image Configuration\", fontsize=30)\n",
    "#plt.ylabel(\"$H_0\\:(\\\\textbf{km Mpc}^{-1}\\:\\\\textbf{s}^{-1})$\")\n",
    "plt.legend(loc='lower right', ncol=3)\n",
    "handles, legend_labels = plt.gca().get_legend_handles_labels()\n",
    "print(handles, legend_labels)\n",
    "#order = [0, 5, 1, 2, 3, 4]\n",
    "#order = [ -1, 1,0, 3, 5, 7, -7, -5, -3]\n",
    "order = [1, -1] #0, 2, 4, 6]\n",
    "plt.legend([handles[idx] for idx in order], [legend_labels[idx] for idx in order], loc='lower right', fontsize=20, ncol=1)\n",
    "plt.savefig('../plots/boxplot_doubles_vs_quads.pdf', bbox_inches='tight', pad_inches=0.1) #dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exposure times <a name=\"exposure_times\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 1-sigma for each exptime, KDE\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    means = np.mean(h0_samples_kde[orbit]['all'], keepdims=True)\n",
    "    #stds = np.std(h0_samples[orbit]['all'], keepdims=True)\n",
    "    upper_sig = np.quantile(h0_samples_kde[orbit]['all'], q=0.5 + 0.341, keepdims=True)\n",
    "    lower_sig = np.quantile(h0_samples_kde[orbit]['all'], q=0.5 - 0.341, keepdims=True)\n",
    "    plt.errorbar(orbit_i , means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=5, capsize=10, label='{:s} HST orbit'.format(str(orbit)))\n",
    "    print(orbit, means, means-lower_sig)\n",
    "if False:\n",
    "    # 1-sigma for each exptime, lognormal\n",
    "    for orbit_i, orbit in enumerate(orbits_available):\n",
    "        means = np.mean(h0_samples_lognormal[orbit]['all'], keepdims=True)\n",
    "        #stds = np.std(h0_samples[orbit]['all'], keepdims=True)\n",
    "        upper_sig = np.quantile(h0_samples_lognormal[orbit]['all'], q=0.5 + 0.341, keepdims=True)\n",
    "        lower_sig = np.quantile(h0_samples_lognormal[orbit]['all'], q=0.5 - 0.341, keepdims=True)\n",
    "        plt.errorbar(orbit_i + 0.05 , means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=5, capsize=10, label='Lognormal, {:s}'.format(orbit_to_seconds[orbit]))\n",
    "        print(orbit, means, means-lower_sig)\n",
    "\n",
    "    for orbit_i, orbit in enumerate(orbits_available):\n",
    "        means = np.mean(h0_samples_normal[orbit]['all'], keepdims=True)\n",
    "        #stds = np.std(h0_samples[orbit]['all'], keepdims=True)\n",
    "        upper_sig = np.quantile(h0_samples_normal[orbit]['all'], q=0.5 + 0.341, keepdims=True)\n",
    "        lower_sig = np.quantile(h0_samples_normal[orbit]['all'], q=0.5 - 0.341, keepdims=True)\n",
    "        eb = plt.errorbar(orbit_i + 0.05, means, yerr=[means-lower_sig, upper_sig-means], fmt='o', color=orbit_to_color[orbit], lw=3, capsize=10, label='Normal, {:s}'.format(orbit_to_seconds[orbit]))\n",
    "        eb[-1][0].set_linestyle('--')\n",
    "\n",
    "if include_prec_ceiling:\n",
    "    prec_means = np.mean(h0_samples_kde['prec']['all'], keepdims=True)\n",
    "    prec_upper_sig = np.quantile(h0_samples_kde['prec']['all'], q=0.5 + 0.341, keepdims=True) \n",
    "    prec_lower_sig = np.quantile(h0_samples_kde['prec']['all'], q=0.5 - 0.341, keepdims=True) \n",
    "    #plt.errorbar(conf_to_x_pos['all'] + 0.2, prec_means, yerr=[prec_upper_sig-prec_means, prec_means-prec_lower_sig], fmt='o', color='tab:gray', alpha=1.0, lw=3, capsize=5, label=r'Time delay precision ceiling')\n",
    "    #plt.plot(orbit_i, prec_means, color='tab:gray', linestyle='dotted')\n",
    "plt.fill_between([-0.3, 1, 2.2], prec_lower_sig, prec_upper_sig, color='tab:gray', alpha=0.4, label='Time delay precision ceiling')\n",
    "\n",
    "plt.plot(np.NaN, np.NaN, '-', color='none', label=' ')\n",
    "\n",
    "plt.xticks(np.arange(len(orbits_available)), labels=['{:s}'.format(str(o)) for o in orbits_available], fontsize=25)\n",
    "plt.yticks(np.arange(68, 72 + 1, 0.5))\n",
    "\n",
    "plt.xlim([-0.2, 2.2])\n",
    "plt.ylim([68, 72])\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "ax.grid(axis=\"y\", color=\"black\", which='minor', alpha=.2,  linestyle=(0, (1, 1)))\n",
    "\n",
    "#plt.title(\"Combined $H_0$ predictions\")\n",
    "plt.axhline(70.0, c='k', linestyle='--', label='Truth = 70 km Mpc$^{-1}$ s$^{-1}$')\n",
    "plt.ylabel(\"$H_0$ (km Mpc$^{-1}$ s$^{-1}$)\", fontsize=30)\n",
    "plt.xlabel(\"Exposure time (HST orbit)\", fontsize=30)\n",
    "#plt.legend(loc='lower right')\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1, 2]\n",
    "\n",
    "print(handles, labels)#set_color('#da5054')\n",
    "\n",
    "handles[-1]\n",
    "\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc='upper left', ncol=1, fontsize=25)\n",
    "plt.savefig('../plots/boxplot_exptime.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma retrieval vs. Einstein ring brightness <a name=\"gamma\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, let's merge `metadata` (true parameters) with `summary` (containing the Einstein brightness bin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_version_info(version_id, n_test=200):\n",
    "    version_dir = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(version_id)\n",
    "    test_cfg_path = os.path.join(version_dir, 'mcmc_default.json')\n",
    "    test_cfg = TestConfig.from_file(test_cfg_path)\n",
    "    baobab_cfg = BaobabConfig.from_file(test_cfg.data.test_baobab_cfg_path)\n",
    "    #train_val_cfg = TrainValConfig.from_file(test_cfg.train_val_config_file_path)\n",
    "    # Read in truth metadata\n",
    "    metadata = pd.read_csv(os.path.join(baobab_cfg.out_dir, 'metadata.csv'), index_col=None, nrows=n_test)\n",
    "    # Read in summary\n",
    "    summary = pd.read_csv(os.path.join(version_dir, 'summary.csv'), index_col=None, nrows=n_test)\n",
    "    # Assign lens ID based on the row index of metadata, for merging with summary\n",
    "    metadata['id'] = metadata.index\n",
    "    summary_pred = summary.merge(metadata, on='id', suffixes=['', '_meta'], how='inner')\n",
    "    # Precision ceiling\n",
    "    prec_version_dir = '/home/jwp/stage/sl/h0rton/experiments/v{:d}'.format(prec_version_id)\n",
    "    prec_summary = pd.read_csv(os.path.join(prec_version_dir, 'ering_summary.csv'), index_col=None, nrows=n_test)\n",
    "    summary_pred['lensed_E_ring_mag'] = prec_summary['lensed_E_ring_mag'].values\n",
    "    \n",
    "    lensed_ring_bins = np.quantile(summary_pred['lensed_E_ring_mag'].values, [0.25, 0.5, 0.75, 1])\n",
    "    print(lensed_ring_bins, np.min(summary_pred['lensed_E_ring_mag'].values))\n",
    "    lensed_ring_bins[-1] += 0.1 # buffer \n",
    "    summary_pred['lensed_ring_bin'] = np.digitize(summary_pred['lensed_E_ring_mag'].values, lensed_ring_bins)\n",
    "    # Note that metadata stores the absolute source position, so get relative to lens center\n",
    "    summary_pred['src_light_center_x'] -= summary_pred['lens_mass_center_x']\n",
    "    summary_pred['src_light_center_y'] -= summary_pred['lens_mass_center_y'] \n",
    "    print(summary_pred.shape)\n",
    "    #print(summary_pred.columns)\n",
    "    # Read in the MC dropout BNN samples \n",
    "    samples = np.load('/home/jwp/stage/sl/h0rton/experiments/v{:d}/mcmc_default_samples_test_drop=0.001/samples.npy'.format(version_id))\n",
    "    print(samples.shape) # [batch_size, n_walkers=n_dropout_samples, samples_per_dropout, Y_dim]\n",
    "    print(samples.transpose(0, 3, 1, 2).shape) # [batch_size, Y_dim, n_walkers=n_dropout_samples, samples_per_dropout]\n",
    "    n_lenses = samples.shape[0]\n",
    "    mcmc_Y_dim = samples.shape[-1]\n",
    "    n_test = 200\n",
    "    samples = samples.transpose(0, 3, 1, 2).reshape([n_lenses, mcmc_Y_dim, -1])[:n_test]\n",
    "    print(samples.shape)\n",
    "    print(samples[0, 4, :5], train_val_cfg.data.Y_cols[4]) # 4=gamma column idx, values should be around 2\n",
    "    #reshape([200, len(train_val_cfg.data.Y_cols), -1])\n",
    "\n",
    "    # Store BNN predictions (expected value and spread) as dataframes\n",
    "    pred_mean = np.mean(samples, axis=-1) # expected value\n",
    "    pred_std = np.std(samples, axis=-1)\n",
    "    params_to_remove = [] #'src_light_R_sersic'] \n",
    "    mcmc_Y_cols = [col for col in train_val_cfg.data.Y_cols if col not in params_to_remove]\n",
    "    pred_mean = pd.DataFrame(pred_mean, columns=mcmc_Y_cols)\n",
    "    pred_std = pd.DataFrame(pred_std, columns=mcmc_Y_cols)\n",
    "    pred_mean = sim_utils.add_qphi_columns(pred_mean)\n",
    "    pred_mean = sim_utils.add_gamma_psi_ext_columns(pred_mean)\n",
    "    \n",
    "    version_info = dict(\n",
    "        summary_pred=summary_pred,\n",
    "        samples=samples,\n",
    "        pred_mean=pred_mean,\n",
    "        pred_std=pred_std\n",
    "    )\n",
    "    return version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "param_name = 'lens_mass_gamma'\n",
    "param_label = '$\\gamma_{\\mathrm{lens}}$'\n",
    "\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    version_info = get_version_info(orbit_to_ver[orbit])\n",
    "    # Bias = predicted - truth\n",
    "    version_info['summary_pred']['{:s}_bias'.format(param_name)] = version_info['pred_mean'][param_name] - version_info['summary_pred'][param_name]\n",
    "    centers = []\n",
    "    yerr_lower = []\n",
    "    yerr_upper = []\n",
    "    pm = [] # plus minus (error bars)\n",
    "    for bin_i in range(4): # again, brightest is bin 0\n",
    "        binned_pred = version_info['summary_pred'][version_info['summary_pred']['lensed_ring_bin']==bin_i]\n",
    "        binned_std = version_info['pred_std'][version_info['summary_pred']['lensed_ring_bin']==bin_i]\n",
    "        center = np.average(binned_pred['{:s}_bias'.format(param_name)].values, weights=1.0/binned_std[param_name].values**2.0)\n",
    "        weighted_std = np.average((binned_pred['{:s}_bias'.format(param_name)].values - center)**2.0, weights=1.0/binned_std[param_name].values**2.0)**0.5\n",
    "        #print(center, weighted_std)\n",
    "        centers.append(center)\n",
    "        pm.append(weighted_std)\n",
    "        yerr_lower.append(center - weighted_std)\n",
    "        yerr_upper.append(center + weighted_std)\n",
    "    orbit_label = '{:s} HST orbit'.format(str(orbit)) if orbit < 2 else '{:s} HST orbits'.format(str(orbit))\n",
    "    plt.errorbar(np.array([3, 2, 1, 0]) + orbit_i*0.1 - 0.2, centers, yerr=pm, fmt='o', color=orbit_to_color[orbit], alpha=1.0, lw=3, capsize=5, label=orbit_label)\n",
    "\n",
    "#labels = ['Fainter',  'Brighter']\n",
    "#plt.xticks([0, 2.8], labels=labels, fontsize=15)\n",
    "\n",
    "labels = ['[22.8, 21.6)', '[21.6, 20.3)', '[20.3, 19.1)', '[19.1, 17.5]']\n",
    "plt.xticks(np.array([0, 1, 2, 3]) - 0.1, labels=labels, fontsize=15)\n",
    "\n",
    "#print(centers, yerr_lower, yerr_upper)\n",
    "plt.xlabel(\"Einstein ring brightness bins (mag)\", fontsize=20)\n",
    "\n",
    "plt.axhline(0, c='k', linestyle='--')\n",
    "plt.yticks(np.linspace(-0.1, 0.1, 11), fontsize=15)\n",
    "plt.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "\n",
    "#plt.minorticks_on()\n",
    "plt.ylabel('Weighted bias in {:s}'.format(param_label), fontsize=20)\n",
    "plt.legend(loc='lower left', framealpha=1.0, bbox_to_anchor=(-0.05, 1), ncol=3, columnspacing=0.1, fontsize=15)\n",
    "plt.savefig('../plots/gamma_ring_brightness.pdf', bbox_inches='tight', pad_inches=0.1) #dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma retrieval vs. other metrics <a name=\"gamma_other_metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the gamma retreival depend on the image configuration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "param_name = 'lens_mass_gamma'\n",
    "param_label = '$\\gamma_{\\mathrm{lens}}$'\n",
    "\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    version_info = get_version_info(orbit_to_ver[orbit])\n",
    "    # Bias = predicted - truth\n",
    "    version_info['summary_pred']['{:s}_bias'.format(param_name)] = version_info['pred_mean'][param_name] - version_info['summary_pred'][param_name]\n",
    "    centers = []\n",
    "    yerr_lower = []\n",
    "    yerr_upper = []\n",
    "    pm = [] # plus minus (error bars)\n",
    "    for n_img in [2, 4]: # smallest separation is bin 0\n",
    "        binned_pred = version_info['summary_pred'][version_info['summary_pred']['n_img']==n_img]\n",
    "        binned_std = version_info['pred_std'][version_info['summary_pred']['n_img']==n_img]\n",
    "        center = np.average(binned_pred['{:s}_bias'.format(param_name)].values, weights=1.0/binned_std[param_name].values**2.0)\n",
    "        weighted_std = np.average((binned_pred['{:s}_bias'.format(param_name)].values - center)**2.0, weights=1.0/binned_std[param_name].values**2.0)**0.5\n",
    "        #print(center, weighted_std)\n",
    "        centers.append(center)\n",
    "        pm.append(weighted_std)\n",
    "        yerr_lower.append(center - weighted_std)\n",
    "        yerr_upper.append(center + weighted_std)\n",
    "    plt.errorbar(np.array([0, 1]) + orbit_i*0.1 - 0.2, centers, yerr=pm, fmt='o', color=orbit_to_color[orbit], alpha=1.0, lw=3, capsize=5, label=orbit_to_seconds[orbit])\n",
    "\n",
    "labels = ['Doubles', 'Quads']\n",
    "plt.xticks([-0.1, 0.9], labels=labels, fontsize=15)\n",
    "#print(centers, yerr_lower, yerr_upper)\n",
    "plt.xlabel(\"Image separation bins\")\n",
    "plt.xlim([-0.5, 1.3])\n",
    "\n",
    "plt.axhline(0, c='k', linestyle='--')\n",
    "plt.yticks(np.linspace(-0.12, 0.12, 13), fontsize=15)\n",
    "plt.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "\n",
    "#plt.minorticks_on()\n",
    "plt.ylabel('Weighted bias in {:s}'.format(param_label))\n",
    "plt.legend(loc='lower right', columnspacing=0.1, ncol=3, fontsize=15)\n",
    "plt.savefig('../plots/gamma_theta_E.pdf', bbox_inches='tight', pad_inches=0.1) #dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the lens axis ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "param_name = 'lens_mass_gamma'\n",
    "param_label = '$\\gamma_{\\mathrm{lens}}$'\n",
    "\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    version_info = get_version_info(orbit_to_ver[orbit])\n",
    "    # Bias = predicted - truth\n",
    "    version_info['summary_pred']['{:s}_bias'.format(param_name)] = version_info['pred_mean'][param_name] - version_info['summary_pred'][param_name]\n",
    "    e = (version_info['summary_pred']['lens_mass_e1'].values**2.0 + version_info['summary_pred']['lens_mass_e2'].values**2.0)**0.5\n",
    "    handpicked_metric = (1-e)/(1+e)\n",
    "    handpicked_metric_bins = np.quantile(handpicked_metric, [0.25, 0.5, 0.75, 1])\n",
    "    handpicked_metric_bins[-1] += 1.e-7 # buffer \n",
    "    version_info['summary_pred']['handpicked_metric_bins'] = np.digitize(handpicked_metric, handpicked_metric_bins)\n",
    "    print(handpicked_metric_bins, np.min(handpicked_metric))\n",
    "    centers = []\n",
    "    yerr_lower = []\n",
    "    yerr_upper = []\n",
    "    pm = [] # plus minus (error bars)\n",
    "    for bin_i in range(4): # again, brightest is bin 0\n",
    "        binned_pred = version_info['summary_pred'][version_info['summary_pred']['handpicked_metric_bins']==bin_i]\n",
    "        binned_std = version_info['pred_std'][version_info['summary_pred']['handpicked_metric_bins']==bin_i]\n",
    "        center = np.average(binned_pred['{:s}_bias'.format(param_name)].values, weights=1.0/binned_std[param_name].values**2.0)\n",
    "        weighted_std = np.average((binned_pred['{:s}_bias'.format(param_name)].values - center)**2.0, weights=1.0/binned_std[param_name].values**2.0)**0.5\n",
    "        #print(center, weighted_std)\n",
    "        centers.append(center)\n",
    "        pm.append(weighted_std)\n",
    "        yerr_lower.append(center - weighted_std)\n",
    "        yerr_upper.append(center + weighted_std)\n",
    "    orbit_label = '{:s} HST orbit'.format(str(orbit)) if orbit < 2 else '{:s} HST orbits'.format(str(orbit))\n",
    "    plt.errorbar(np.array([0, 1, 2, 3]) + orbit_i*0.1 - 0.2, centers, yerr=pm, fmt='o', color=orbit_to_color[orbit], alpha=1.0, lw=3, capsize=5, label=orbit_label)\n",
    "\n",
    "#labels = ['More elliptical', 'More spherical']\n",
    "#plt.xticks([0.1, 2.7], labels=labels, fontsize=15)\n",
    "\n",
    "labels = ['[0.3, 0.6)', '[0.6, 0.7)', '[0.7, 0.8)', '[0.8, 1]']\n",
    "plt.xticks(np.array([0, 1, 2, 3]) - 0.1, labels=labels, fontsize=15)\n",
    "\n",
    "#print(centers, yerr_lower, yerr_upper)\n",
    "plt.xlabel(\"Lens mass axis ratio bins\", fontsize=20)\n",
    "\n",
    "plt.axhline(0, c='k', linestyle='--')\n",
    "plt.yticks(np.linspace(-0.12, 0.12, 13), fontsize=15)\n",
    "plt.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "\n",
    "#plt.minorticks_on()\n",
    "plt.ylabel('Weighted bias in {:s}'.format(param_label), fontsize=20)\n",
    "plt.legend(loc='lower left', framealpha=1.0, bbox_to_anchor=(-0.1, 1), ncol=3, columnspacing=0.075, fontsize=15)\n",
    "plt.savefig('../plots/gamma_ellipticity.pdf', bbox_inches='tight', pad_inches=0.1) #dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Einstein radius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "param_name = 'lens_mass_gamma'\n",
    "param_label = '$\\gamma_{\\mathrm{lens}}$'\n",
    "\n",
    "for orbit_i, orbit in enumerate(orbits_available):\n",
    "    version_info = get_version_info(orbit_to_ver[orbit])\n",
    "    # Bias = predicted - truth\n",
    "    version_info['summary_pred']['{:s}_bias'.format(param_name)] = version_info['pred_mean'][param_name] - version_info['summary_pred'][param_name]\n",
    "    handpicked_metric = version_info['summary_pred']['lens_mass_theta_E'].values\n",
    "    handpicked_metric_bins = np.quantile(handpicked_metric, [0.25, 0.5, 0.75, 1])\n",
    "    handpicked_metric_bins[-1] += 1.e-7 # buffer \n",
    "    version_info['summary_pred']['handpicked_metric_bins'] = np.digitize(handpicked_metric, handpicked_metric_bins)\n",
    "    print(handpicked_metric_bins, np.min(handpicked_metric))\n",
    "    centers = []\n",
    "    yerr_lower = []\n",
    "    yerr_upper = []\n",
    "    pm = [] # plus minus (error bars)\n",
    "    for bin_i in range(4): # smallest separation is bin 0\n",
    "        binned_pred = version_info['summary_pred'][version_info['summary_pred']['handpicked_metric_bins']==bin_i]\n",
    "        binned_std = version_info['pred_std'][version_info['summary_pred']['handpicked_metric_bins']==bin_i]\n",
    "        center = np.average(binned_pred['{:s}_bias'.format(param_name)].values, weights=1.0/binned_std[param_name].values**2.0)\n",
    "        weighted_std = np.average((binned_pred['{:s}_bias'.format(param_name)].values - center)**2.0, weights=1.0/binned_std[param_name].values**2.0)**0.5\n",
    "        #print(center, weighted_std)\n",
    "        centers.append(center)\n",
    "        pm.append(weighted_std)\n",
    "        yerr_lower.append(center - weighted_std)\n",
    "        yerr_upper.append(center + weighted_std)\n",
    "    orbit_label = '{:s} HST orbit'.format(str(orbit)) if orbit < 2 else '{:s} HST orbits'.format(str(orbit))\n",
    "    plt.errorbar(np.array([0, 1, 2, 3]) + orbit_i*0.1 - 0.2, centers, yerr=pm, fmt='o', color=orbit_to_color[orbit], alpha=1.0, lw=3, capsize=5, label=orbit_label)\n",
    "\n",
    "#labels = ['Smaller separation', 'Bigger separation']\n",
    "#plt.xticks([0.2, 2.6], labels=labels, fontsize=15)\n",
    "\n",
    "labels = ['[0.8, 1.0)', '[1.0, 1.1)', '[1.1, 1.2)', '[1.2, 1.4]']\n",
    "plt.xticks(np.arange(4) - 0.1, labels=labels, fontsize=15)\n",
    "\n",
    "plt.xlabel(r\"Einstein radius ($''$)\", fontsize=20)\n",
    "#plt.xlim([-0.5, 3.5])\n",
    "\n",
    "plt.axhline(0, c='k', linestyle='--')\n",
    "plt.yticks(np.linspace(-0.12, 0.12, 13), fontsize=15)\n",
    "plt.grid(axis=\"y\", color=\"black\", alpha=.5,  linestyle='dotted')\n",
    "\n",
    "#plt.minorticks_on()\n",
    "plt.ylabel('Weighted bias in {:s}'.format(param_label), fontsize=20)\n",
    "plt.legend(loc='lower left', framealpha=1.0, bbox_to_anchor=(-0.1, 1), ncol=3, columnspacing=0.075, fontsize=15)\n",
    "plt.savefig('../plots/gamma_theta_E.pdf', bbox_inches='tight', pad_inches=0.1) #dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (baobab)",
   "language": "python",
   "name": "baobab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
